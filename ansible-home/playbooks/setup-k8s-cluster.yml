---
- name: Initialize Kubernetes control plane
  hosts: k8s_control_plane
  become: yes
  tasks:
    - name: Ensure containerd is enabled and running
      systemd:
        name: containerd
        state: started
        enabled: yes
        daemon_reload: yes

    - name: Wait for containerd to be ready
      command: ctr version
      register: ctr_check
      until: ctr_check.rc == 0
      retries: 5
      delay: 3

    - name: Check if Kubernetes is already initialized
      stat:
        path: /etc/kubernetes/admin.conf
      register: k8s_initialized

    - name: Test if cluster is healthy
      command: kubectl get nodes --kubeconfig=/etc/kubernetes/admin.conf
      register: cluster_health
      failed_when: false
      changed_when: false
      when: k8s_initialized.stat.exists

    - name: Determine if cluster needs reset
      set_fact:
        needs_reset: "{{ not k8s_initialized.stat.exists or (k8s_initialized.stat.exists and cluster_health.rc != 0) }}"

    - name: Reset Kubernetes cluster if needed
      command: kubeadm reset -f
      when: needs_reset | bool
      ignore_errors: yes

    - name: Remove CNI config
      file:
        path: /etc/cni/net.d
        state: absent
      when: needs_reset | bool

    - name: Remove old kubernetes config
      file:
        path: "{{ item }}"
        state: absent
      loop:
        - /etc/kubernetes
        - /var/lib/etcd
        - /var/lib/kubelet
      when: needs_reset | bool

    - name: Stop kubelet before reinit
      systemd:
        name: kubelet
        state: stopped
      when: needs_reset | bool

    - name: Recreate CNI directory
      file:
        path: /etc/cni/net.d
        state: directory
        mode: '0755'

    - name: Initialize Kubernetes cluster
      command: >
        kubeadm init
        --pod-network-cidr=10.244.0.0/16
        --apiserver-advertise-address={{ ansible_facts.default_ipv4.address }}
      when: needs_reset | bool
      register: kubeadm_init
      failed_when: false

    - name: Display kubeadm init output if it failed
      debug:
        var: kubeadm_init
      when: kubeadm_init.rc is defined and kubeadm_init.rc != 0

    - name: Fail if kubeadm init failed
      fail:
        msg: "Kubeadm init failed. Check the output above."
      when: kubeadm_init.rc is defined and kubeadm_init.rc != 0

    - name: Wait for kubelet to be running
      systemd:
        name: kubelet
        state: started
      register: kubelet_status
      until: kubelet_status is succeeded
      retries: 10
      delay: 5

    - name: Check kubelet status
      command: systemctl status kubelet
      register: kubelet_check
      changed_when: false
      failed_when: false

    - name: Display kubelet status
      debug:
        var: kubelet_check.stdout_lines

    - name: Create .kube directory for root
      file:
        path: /root/.kube
        state: directory
        mode: '0755'

    - name: Copy admin.conf to root's kube config
      copy:
        src: /etc/kubernetes/admin.conf
        dest: /root/.kube/config
        remote_src: yes
        mode: '0600'

    - name: Create .kube directory for ansible user
      file:
        path: /home/{{ ansible_user }}/.kube
        state: directory
        owner: "{{ ansible_user }}"
        group: "{{ ansible_user }}"
        mode: '0755'

    - name: Copy admin.conf to ansible user's kube config
      copy:
        src: /etc/kubernetes/admin.conf
        dest: /home/{{ ansible_user }}/.kube/config
        remote_src: yes
        owner: "{{ ansible_user }}"
        group: "{{ ansible_user }}"
        mode: '0600'

    - name: Check static pod manifests
      command: ls -la /etc/kubernetes/manifests/
      register: manifests
      changed_when: false

    - name: Display control plane manifests
      debug:
        var: manifests.stdout_lines

    - name: Wait for Kubernetes API server to be ready
      become_user: "{{ ansible_user }}"
      command: kubectl cluster-info
      environment:
        KUBECONFIG: /home/{{ ansible_user }}/.kube/config
      register: api_status
      until: api_status.rc == 0
      retries: 30
      delay: 10
      changed_when: false
      failed_when: false

    - name: Check kubelet logs if API server failed
      command: journalctl -u kubelet -n 50 --no-pager
      register: kubelet_logs
      when: api_status.rc != 0
      changed_when: false

    - name: Display kubelet logs
      debug:
        var: kubelet_logs.stdout_lines
      when: api_status.rc != 0

    - name: Check containerd logs if API server failed
      command: journalctl -u containerd -n 30 --no-pager
      register: containerd_logs
      when: api_status.rc != 0
      changed_when: false

    - name: Display containerd logs
      debug:
        var: containerd_logs.stdout_lines
      when: api_status.rc != 0

    - name: Fail if API server is not ready
      fail:
        msg: "Kubernetes API server failed to start. Check the logs above."
      when: api_status.rc != 0

    - name: Install Flannel CNI plugin
      become_user: "{{ ansible_user }}"
      command: kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml
      environment:
        KUBECONFIG: /home/{{ ansible_user }}/.kube/config

    - name: Generate join token
      command: kubeadm token create --print-join-command
      register: join_command

    - name: Save join command to local file
      copy:
        content: |
          #!/bin/bash
          {{ join_command.stdout }}
        dest: /tmp/k8s-join-command.sh
        mode: '0755'

    - name: Fetch join command to control machine
      fetch:
        src: /tmp/k8s-join-command.sh
        dest: /tmp/k8s-join-command.sh
        flat: yes

- name: Join worker nodes to the cluster
  hosts: k8s_workers
  become: yes
  tasks:
    - name: Ensure containerd is enabled and running
      systemd:
        name: containerd
        state: started
        enabled: yes
        daemon_reload: yes

    - name: Wait for containerd to be ready
      command: ctr version
      register: ctr_check
      until: ctr_check.rc == 0
      retries: 5
      delay: 3

    - name: Check if node is already joined
      stat:
        path: /etc/kubernetes/kubelet.conf
      register: kubelet_conf

    - name: Copy join command to worker
      copy:
        src: /tmp/k8s-join-command.sh
        dest: /tmp/k8s-join-command.sh
        mode: '0755'
      when: not kubelet_conf.stat.exists

    - name: Join worker node to cluster
      command: /tmp/k8s-join-command.sh
      when: not kubelet_conf.stat.exists

- name: Verify cluster status
  hosts: k8s_control_plane
  become: yes
  tasks:
    - name: Wait for all nodes to be ready
      become_user: "{{ ansible_user }}"
      command: kubectl get nodes
      environment:
        KUBECONFIG: /home/{{ ansible_user }}/.kube/config
      register: node_status
      until: node_status.stdout.find("NotReady") == -1
      retries: 30
      delay: 10

    - name: Display cluster nodes
      become_user: "{{ ansible_user }}"
      command: kubectl get nodes -o wide
      environment:
        KUBECONFIG: /home/{{ ansible_user }}/.kube/config
      register: cluster_nodes

    - name: Show cluster status
      debug:
        var: cluster_nodes.stdout_lines

    - name: Display cluster info
      become_user: "{{ ansible_user }}"
      command: kubectl cluster-info
      environment:
        KUBECONFIG: /home/{{ ansible_user }}/.kube/config
      register: cluster_info

    - name: Show cluster info
      debug:
        var: cluster_info.stdout_lines
